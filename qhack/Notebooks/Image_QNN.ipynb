{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Pyfiles')\n",
    "# Pull in the helper files.\n",
    "from ImageRead import *\n",
    "from QNN import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_o = [1 for i in range(25)]+[0 for i in range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathY=r'../dataset/Original/galaxy/'\n",
    "pathN=r'../dataset/Original/No-galaxy/'\n",
    "nameN=''\n",
    "nameY=''\n",
    "# a1 = imageResize(callImage(5,pathY,nameY),16)\n",
    "# a2 = imageResize(callImage(29,pathY,nameY),16)\n",
    "# # plt.imshow(a1,cmap='gray')\n",
    "# plt.imshow(a2,cmap='gray')\n",
    "# plt.imshow(b1,cmap='gray')\n",
    "# plt.imshow(b2,cmap='gray')\n",
    "inputY=[imageResize(callImage(i+1,pathY,nameY),16) for i in range(25)]\n",
    "inputN=[imageResize(callImage(i+1,pathN,nameN),16) for i in range(25)]\n",
    "input_combine = inputY+inputN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "idx=np.array([int(i) for i in range(50)]).flatten()\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "dataInput = list(input_combine[i] for i in idx )\n",
    "dataTarget = list( imageBinarize(input_combine[i]) for i in idx )\n",
    "\n",
    "data_target_o=list( target_o[i] for i in idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x432 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 5\n",
    "fig, axes = plt.subplots(nrows=2, ncols=n_samples_show, figsize=(20, 6))\n",
    "\n",
    "for i in range(n_samples_show):\n",
    "\n",
    "    axes[0,i].imshow(dataInput[i], cmap='gray')\n",
    "    axes[0,i].set_xticks([])\n",
    "    axes[0,i].set_yticks([])\n",
    "    axes[1,i].imshow(dataInput[i+5], cmap='gray')\n",
    "    axes[1,i].set_xticks([])\n",
    "    axes[1,i].set_yticks([])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.parameter import Parameter\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit.utils import QuantumInstance\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS, SGD,Adam \n",
    "qi = QuantumInstance(Aer.get_backend('statevector_simulator'))\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier, VQC\n",
    "from qiskit.algorithms.optimizers import COBYLA, L_BFGS_B\n",
    "\n",
    "# Model for LBFGS\n",
    "# Combining the circuit together with CircuitQNN\n",
    "np.random.seed(3)\n",
    "\n",
    "\n",
    "nqubits=6\n",
    "num_inputs=256\n",
    "qc = QuantumCircuit(nqubits)\n",
    "\n",
    "# Encoding\n",
    "param_x=[];\n",
    "for i in range(num_inputs):\n",
    "    param_x.append(Parameter('x'+str(i)))\n",
    "for i in range(8):\n",
    "    param_x.append(np.pi/2)\n",
    "\n",
    "\n",
    "feature_map = encoding(qc,param_x,22)\n",
    "\n",
    "\n",
    "# Optimzing circuit PQC\n",
    "param_y=[];\n",
    "for i in range(nqubits*2):\n",
    "    param_y.append(Parameter('θ'+str(i)))\n",
    "\n",
    "ansatz=circuit15(qc,param_y)\n",
    "\n",
    "qc.append(feature_map, range(nqubits))\n",
    "qc.append(ansatz, range(nqubits))\n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=2, quantum_instance=qi)\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.05)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "X= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01= [data_target_o[i] for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "# traning model accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.05)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "X= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01= [data_target_o[i] for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.70199203491211\n",
      "36.596290588378906\n",
      "35.72026824951172\n",
      "33.646461486816406\n",
      "33.58949279785156\n",
      "33.4216194152832\n",
      "33.05319595336914\n",
      "32.63026809692383\n",
      "32.33580780029297\n",
      "32.09917068481445\n",
      "31.878211975097656\n",
      "31.671499252319336\n",
      "31.483640670776367\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "# start training\n",
    "\n",
    "model2.train()    # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()                                  # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())\n",
    "    loss.backward()                                        # backward pass\n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning model accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19240/857769905.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mf_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormlaizeData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataInput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my011\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata_target_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19240/857769905.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mf_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnormlaizeData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataInput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my011\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata_target_o\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# define optimizer and loss function\n",
    "from torch import Tensor\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.06)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "X= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01= [data_target_o[i] for i in range(50)]\n",
    "\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.560748100280762\n",
      "10.555519104003906\n",
      "10.322396278381348\n",
      "10.263618469238281\n",
      "10.231043815612793\n",
      "10.19247817993164\n",
      "10.145801544189453\n",
      "10.094972610473633\n",
      "10.045539855957031\n",
      "10.000255584716797\n",
      "9.959122657775879\n",
      "9.921398162841797\n",
      "9.886467933654785\n",
      "9.853927612304688\n",
      "9.823494911193848\n",
      "9.79495906829834\n",
      "9.768142700195312\n",
      "9.742895126342773\n",
      "9.719085693359375\n",
      "9.696598052978516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10.5607, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "# start training\n",
    "\n",
    "model2.train()    # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()                                  # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())\n",
    "    loss.backward()                                        # backward pass\n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# traning model accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "from torch import Tensor\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.07)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "X= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01= [data_target_o[i] for i in range(50)]\n",
    "\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "# start training\n",
    "\n",
    "model2.train()    # set model to training mode\n",
    "\n",
    "# define objective function\n",
    "def closure():\n",
    "    optimizer.zero_grad()                                  # initialize gradient\n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())\n",
    "    loss.backward()                                        # backward pass\n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer\n",
    "optimizer.step(closure)\n",
    "optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning model accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "target_o = [1 for i in range(25)]+[0 for i in range(25)]\n",
    "\n",
    "pathY=r'../dataset/Original/galaxy1/'\n",
    "pathN=r'../dataset/Original/no-galaxy1/'\n",
    "nameN=''\n",
    "nameY=''\n",
    "inputY=[imageResize(callImage(i+1,pathY,nameY),16) for i in range(25)]\n",
    "inputN=[imageResize(callImage(i+1,pathN,nameN),16) for i in range(25)]\n",
    "input_combine = inputY+inputN\n",
    "\n",
    "np.random.seed(0)\n",
    "idx=np.array([int(i) for i in range(50)]).flatten()\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "dataInput = list(input_combine[i] for i in idx )\n",
    "dataTarget = list( imageBinarize(input_combine[i]) for i in idx )\n",
    "\n",
    "data_target_o=list( target_o[i] for i in idx )\n",
    "\n",
    "Xtest= [normlaizeData(dataInput[i].flatten()) for i in range(25)]\n",
    "y01test= [data_target_o[i] for i in range(25)]\n",
    "\n",
    "Xtest1= [normlaizeData(dataInput[i].flatten()) for i in range(50)]\n",
    "y01test1= [data_target_o[i] for i in range(50)]\n",
    "\n",
    "y_predict = []\n",
    "for x in Xtest:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy25data:', sum(y_predict == np.array(y01test))/len(np.array(y01test)))\n",
    "\n",
    "y_predict1 = []\n",
    "for x in Xtest1:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict1 += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy50data:', sum(y_predict1 == np.array(y01test1))/len(np.array(y01test1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7085d7f3a85dff14807db3b039303f4d3e7814f3ae962158c22b2b6462c5d354"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
